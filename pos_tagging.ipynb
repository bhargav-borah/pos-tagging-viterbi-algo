{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ksAMZnBMX1GF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punct = set(string.punctuation)\n",
        "\n",
        "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
        "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
        "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
        "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
      ],
      "metadata": {
        "id": "xHzNtYuchUZI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_unk(token):\n",
        "\n",
        "  if any(char.isdigit() for char in token):\n",
        "    return '--unk_digit--'\n",
        "\n",
        "  elif any(char in punct for char in token):\n",
        "    return '--unk_punct--'\n",
        "\n",
        "  elif any(char.isupper() for char in token):\n",
        "    return '--unk__upper--'\n",
        "\n",
        "  elif any(token.endswith(suffix) for suffix in noun_suffix):\n",
        "    return '--unk_noun--'\n",
        "\n",
        "  elif any(token.endswith(suffix) for suffix in verb_suffix):\n",
        "    return '--unk_verb--'\n",
        "\n",
        "  elif any(token.endswith(suffix) for suffix in adj_suffix):\n",
        "    return '--unk_adj--'\n",
        "\n",
        "  elif any(token.endswith(suffix) for suffix in adv_suffix):\n",
        "    return '--unk_adv--'\n",
        "\n",
        "  return '--unk--'"
      ],
      "metadata": {
        "id": "y0C8yWtwheqe"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(vocab, file_path):\n",
        "\n",
        "  original, preprocessed = [], []\n",
        "\n",
        "  with open(file_path, 'r') as f:\n",
        "\n",
        "    for idx, word in enumerate(f):\n",
        "\n",
        "      if not word.split():\n",
        "        original.append(word.strip())\n",
        "        word = '--n--'\n",
        "        preprocessed.append(word)\n",
        "\n",
        "      elif word.strip() not in vocab:\n",
        "        original.append(word.strip())\n",
        "        word = assign_unk(word.strip())\n",
        "        preprocessed.append(word)\n",
        "\n",
        "      else:\n",
        "        original.append(word.strip())\n",
        "        preprocessed.append(word.strip())\n",
        "\n",
        "  return original, preprocessed"
      ],
      "metadata": {
        "id": "0OHi20wzhfI8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_tag(vocab, word_tag):\n",
        "\n",
        "  if not word_tag.split():\n",
        "    word = '--n--'\n",
        "    tag = '--s--'\n",
        "\n",
        "    return word, tag\n",
        "\n",
        "  else:\n",
        "    word, tag = word_tag.split()\n",
        "    if word not in vocab:\n",
        "      word = assign_unk(word)\n",
        "\n",
        "    return word, tag\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "vHTWCLolqFgG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szgtGBH5hfRN"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEnXEiOChfY8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/WSJ_02-21.pos', 'r') as f:\n",
        "  training_corpus = f.readlines()\n",
        "\n",
        "training_corpus[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQhfIM3nYtE8",
        "outputId": "c285c71b-1348-47c5-80b9-7d206c363209"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/hmm_vocab.txt', 'r') as f:\n",
        "  vocab_l = f.read().split('\\n')"
      ],
      "metadata": {
        "id": "8rCzTRHmZLe_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab_l[:50], vocab_l[-50:]"
      ],
      "metadata": {
        "id": "sulXVVD0ZgJG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "\n",
        "for i, word in enumerate(sorted(vocab_l)):\n",
        "  vocab[word] = i"
      ],
      "metadata": {
        "id": "jTbfGb25akGq"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab"
      ],
      "metadata": {
        "id": "qA2fIg44ZhK0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/WSJ_24.pos', 'r') as f:\n",
        "  test_corpus = f.readlines()"
      ],
      "metadata": {
        "id": "tTP5AKFaa68R"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_corpus"
      ],
      "metadata": {
        "id": "b1cGL-M5bQM-"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/test.words', 'r') as f:\n",
        "#   for idx, word in enumerate(f):\n",
        "#     print(' | ', word, ' | ', word.split())"
      ],
      "metadata": {
        "id": "aqaKsQXieGAp"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, preprocessed = preprocess(vocab, '/content/test.words')"
      ],
      "metadata": {
        "id": "AB_D4HqObQ5M"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessed"
      ],
      "metadata": {
        "id": "1zKEoILCg942"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word_tag in training_corpus:\n",
        "  word = word_tag.split()[0]\n",
        "  tag = word_tag.split()[1]\n",
        "  print(word)\n",
        "  print(tag)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38PK5r6fkA0j",
        "outputId": "5adca8e2-e9ff-41f9-eb01-6480c9e6e7da"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In\n",
            "IN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dictionaries(vocab, training_corpus):\n",
        "  tag_counts = defaultdict(int)\n",
        "  transition_counts = defaultdict(int)\n",
        "  emission_counts = defaultdict(int)\n",
        "\n",
        "  prev_tag = '--s--'\n",
        "  iter = 0\n",
        "\n",
        "  for word_tag in training_corpus:\n",
        "    iter += 1\n",
        "    if iter % 10000 == 0:\n",
        "      print(f'Words traversed = {iter}')\n",
        "\n",
        "    word, tag = get_word_tag(vocab, word_tag)\n",
        "\n",
        "    transition_counts[(prev_tag, tag)] += 1\n",
        "    emission_counts[(tag, word)] += 1\n",
        "    tag_counts[tag] += 1\n",
        "\n",
        "    prev_tag = tag\n",
        "\n",
        "  return transition_counts, emission_counts, tag_counts"
      ],
      "metadata": {
        "id": "BVncLKIHlh30"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transition_counts, emission_counts, tag_counts = create_dictionaries(training_corpus, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "j4DH2SrToY0H",
        "outputId": "74b6c7f3-af7a-4c4d-8e9d-c6a57ca996e0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'split'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-9844f5ee4cec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransition_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memission_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dictionaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-83-302fbd151873>\u001b[0m in \u001b[0;36mcreate_dictionaries\u001b[0;34m(training_corpus, vocab, verbose)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# get the word and tag using the get_word_tag helper function (imported from utils_pos.py)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# the function is defined as: get_word_tag(line, vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Increment the transition count for the previous word and tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-6a7c04546feb>\u001b[0m in \u001b[0;36mget_word_tag\u001b[0;34m(vocab, line)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#   return None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"--n--\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"--s--\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word_tag in training_corpus:\n",
        "  word, tag = word_tag.split()[0], word_tag.split()[1]\n",
        "  print(word)\n",
        "  print(tag)\n",
        "  break"
      ],
      "metadata": {
        "id": "ksBEDcKHo-W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3v1mRGIcpJUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}